{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "max_length = 512\n",
    "seed = 3407\n",
    "batch_size = 32\n",
    "num_labels = 13\n",
    "learning_rate = 2e-5\n",
    "epoch_num = 4\n",
    "data_disk_path = \"../dataset/fineTune\"\n",
    "dataset_path = data_disk_path + \"/dataset_\" + str(max_length) + \"_head_only\"\n",
    "model_path = 'bert-base-chinese'\n",
    "#model_path = 'hfl/chinese-bert-wwm'\n",
    "#model_path = 'hfl/chinese-bert-wwm-ext'\n",
    "#model_path = 'hfl/chinese-roberta-wwm-ext'\n",
    "vocab_path = model_path\n",
    "classifier_method = \"default\"\n",
    "# classifier_method = \"concat\"\n",
    "# classifier_method = \"max\"\n",
    "# classifier_method = \"mean\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    return seed\n",
    "\n",
    "seed_everything(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from datasets import load_from_disk\n",
    "\n",
    "train_dataset = load_from_disk(dataset_path)['train']\n",
    "#train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, drop_last=True)\n",
    "len(train_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from accelerate import Accelerator\n",
    "\n",
    "#accelerator = Accelerator()\n",
    "#accelerator = Accelerator(mixed_precision='fp16')\n",
    "accelerator = Accelerator(mixed_precision='bf16')\n",
    "device = accelerator.device\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from BertLastFourLayer import BertLastFourLayer\n",
    "\n",
    "model = BertLastFourLayer(model_path=model_path, num_labels=num_labels,classifier_method=classifier_method).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from transformers import AdamW\n",
    "\n",
    "\n",
    "def get_parameters(model, model_init_lr, multiplier, classifier_lr):\n",
    "    parameters = []\n",
    "    lr = model_init_lr\n",
    "    for layer in range(12, -1, -1):\n",
    "        layer_params = {\n",
    "            'params': [p for n, p in model.named_parameters() if f'encoder.layer.{layer}.' in n],\n",
    "            'lr': lr\n",
    "        }\n",
    "        parameters.append(layer_params)\n",
    "        lr *= multiplier\n",
    "    classifier_params = {\n",
    "        'params': [p for n, p in model.named_parameters() if 'layer_norm' in n or 'linear' in n\n",
    "                   or 'pooling' in n],\n",
    "        'lr': classifier_lr\n",
    "    }\n",
    "    parameters.append(classifier_params)\n",
    "    return parameters\n",
    "\n",
    "\n",
    "parameters = get_parameters(model, 2e-5, 0.95, 1e-4)\n",
    "optimizer = AdamW(parameters, lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import get_linear_schedule_with_warmup\n",
    "\n",
    "#学习率调节器\n",
    "steps_every_epoch = len(train_dataloader)\n",
    "total_train_steps = steps_every_epoch * epoch_num\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0,\n",
    "                                            num_training_steps=total_train_steps)\n",
    "total_train_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "model, optimizer, training_dataloader, scheduler = accelerator.prepare(model, optimizer, train_dataloader, scheduler)\n",
    "accelerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "loss_list = []\n",
    "total_steps = 0\n",
    "\n",
    "\n",
    "# 训练函数\n",
    "def train():\n",
    "    global steps_every_epoch, loss_list, total_steps\n",
    "    model.train()\n",
    "    epoch_train_loss = 0\n",
    "    for batch in tqdm(train_dataloader):\n",
    "        # 正向传播\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "\n",
    "        #低版本transformers库在accelerate库开启混合精度训练后，模型输出的SequenceClassifierOutput不是简单的元组\n",
    "        #其中loss与logits封装方式不同，使用以下代码取出需要\n",
    "        #loss = outputs.loss[\"loss\"]\n",
    "        loss = outputs[0]\n",
    "        temp_loss = loss.item()\n",
    "        epoch_train_loss += loss.item()\n",
    "\n",
    "        # 反向梯度信息\n",
    "        accelerator.backward(loss)\n",
    "\n",
    "        # 参数更新\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        total_steps += 1\n",
    "        if total_steps % 50 == 0:\n",
    "            loss_list.append(temp_loss)\n",
    "\n",
    "    print(\"Epoch: %d, Average training loss: %.4f\" % (epoch, epoch_train_loss / steps_every_epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# 验证函数\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "test_dataset = load_from_disk(dataset_path)['test']\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, drop_last=True)\n",
    "\n",
    "\n",
    "def validation():\n",
    "    confusion_matrix = np.zeros((num_labels, num_labels), dtype=int)\n",
    "    model.eval()\n",
    "    total_eval_loss = 0\n",
    "    total_test_steps = len(test_dataloader)\n",
    "    for batch in tqdm(test_dataloader):\n",
    "        with torch.no_grad():\n",
    "            # 正常传播\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "\n",
    "        #低版本transformers库在accelerate库开启混合精度训练后，模型输出的SequenceClassifierOutput不是简单的元组\n",
    "        #其中loss与logits封装方式不同，使用以下代码取出需要\n",
    "        #loss = outputs.loss[\"loss\"]\n",
    "        #logits = outputs.loss[\"logits\"]\n",
    "        loss = outputs[0]\n",
    "        logits = outputs[1]\n",
    "        total_eval_loss += loss.item()\n",
    "        pred_flat = np.argmax(logits.detach().to('cpu').numpy(), axis=1).flatten()\n",
    "        labels_flat = labels.to('cpu').numpy().flatten()\n",
    "        assert len(pred_flat) == len(labels_flat)\n",
    "        for i in range(len(pred_flat)):\n",
    "            confusion_matrix[labels_flat[i]][pred_flat[i]] = confusion_matrix[labels_flat[i]][pred_flat[i]] + 1\n",
    "\n",
    "    TP = np.diagonal(confusion_matrix)\n",
    "    accuracy = np.sum(TP) / np.sum(confusion_matrix, axis=(0, 1))\n",
    "    FN = np.sum(confusion_matrix, axis=1) - TP\n",
    "    FP = np.sum(confusion_matrix, axis=0) - TP\n",
    "    precision = np.nan_to_num(TP / (TP + FP))\n",
    "    recall = np.nan_to_num(TP / (TP + FN))\n",
    "    F1_score = np.nan_to_num(2 * precision * recall / (precision + recall))\n",
    "    macro_precision = np.mean(precision)\n",
    "    macro_recall = np.mean(recall)\n",
    "    macro_F1_score = np.mean(F1_score)\n",
    "    weighted_weight = np.array([35, 402, 392, 57, 71, 1840, 164, 114, 199, 337, 217, 124, 44]) / 3996\n",
    "    weighted_precision = np.sum(precision * weighted_weight)\n",
    "    weighted_recall = np.sum(recall * weighted_weight)\n",
    "    weighted_F1_score = np.sum(F1_score * weighted_weight)\n",
    "\n",
    "    aver_test_loss = total_eval_loss / total_test_steps\n",
    "    print(\"-------------------------------\")\n",
    "    print(\"Average testing loss: %.4f\" % aver_test_loss)\n",
    "    print(\"Accuracy: %.4f\" % accuracy)\n",
    "    print(\"macro Precision: %.4f\" % macro_precision)\n",
    "    print(\"macro Recall: %.4f\" % macro_recall)\n",
    "    print(\"macro F1 Score: %.4f\" % macro_F1_score)\n",
    "    print(\"weighted Precision: %.4f\" % weighted_precision)\n",
    "    print(\"weighted Recall: %.4f\" % weighted_recall)\n",
    "    print(\"weighted F1 Score: %.4f\" % weighted_F1_score)\n",
    "    print(\"-------------------------------\")\n",
    "    # 转化为可以直接粘贴到word的表格的格式\n",
    "    result = \"%.4f\\t\" % aver_test_loss + \"%.4f\\t\" % accuracy + \"%.4f\\t\" % macro_precision + \"%.4f\\t\" % macro_recall + \"%.4f\\t\" % macro_F1_score + \"%.4f\\t\" % weighted_precision + \"%.4f\\t\" % weighted_recall + \"%.4f\\t\" % weighted_F1_score\n",
    "    print(result)\n",
    "    with open(\"./result.txt\", \"a\") as f:\n",
    "        f.write(result + \"\\n\")\n",
    "    print(\"-------------------------------\")\n",
    "    print(\"confusion_matrix: \")\n",
    "    for i in range(num_labels):\n",
    "        for j in range(num_labels):\n",
    "            if i == j:\n",
    "                print(\"%4d*\" % confusion_matrix[i][j], end='\\t')\n",
    "            else:\n",
    "                print(\"%5d\" % confusion_matrix[i][j], end='\\t')\n",
    "        print()\n",
    "    print(\"-------------------------------\")\n",
    "\n",
    "    title = model_path.replace(\"/\", \"_\") + classifier_method + dataset_path[-14:] + '_train_loss'\n",
    "    plt.figure(figsize=(20, 8), dpi=80)\n",
    "    plt.plot(range(len(loss_list)), loss_list)\n",
    "    plt.xticks(range(len(loss_list)), [i * 50 for i in range(len(loss_list))], rotation=90)\n",
    "    plt.xlabel(\"step\")\n",
    "    plt.ylabel(\"loss\")\n",
    "    plt.title(title)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(title + '.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "for epoch in range(epoch_num):\n",
    "    print(\"------------Epoch: %d ----------------\" % epoch)\n",
    "    train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "validation()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "#csl_model_path = './csl_model'\n",
    "#model.save_pretrained(csl_model_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
